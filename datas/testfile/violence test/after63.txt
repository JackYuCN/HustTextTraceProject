《自然语言处罚》课程大纲
一、课程名称：自然语言处罚
二、课程本质：选修、理论课
三、学时与学分：40学时（理论学时：32，实验学时：8），2.5学分
四、课程先导课：线性代数（或矩阵论），概率论与数理统计，微积分，Ｃ讲话程序设计（或python/java/c++任何一种编程语言），算法设想与分析
五、课程简介
“自然语言处罚”是一门统筹理论性与实践性的课程，主要蕴涵七个主要部分：自然语言处理综述、讲话模型（N-gram讲话模子）、序列标注问题(Sequence
labellingproblem)、句法分析、语义分析、情感分析、词向量等。其中：自然语言处罚综述关键介绍人工智能发展汗青综述，不同领域自然语言处理应用问题及对策等，自然语言处理基本技术方法概述，其中包含一面机器学习知识，当然语
言处理条理架构，具体任务介绍，歧义问题，经验主义对策等；讲话模子主要包含自然语言处理相关讲话模子基础理论以及相关滑腻处罚技艺等（如N-Gram；链式规则ChainRule等）；序列标注问题(Sequencelabellingproblem)主要学问
点包括序列标注学习及其相关行使等（如分割/连续马尔科夫模子、中文分词、词性标注、定名实体识别等）；句法分析关键包括自然语言中语法分析等基础理论学问等（如上下文无关文法、自上而下句法分析、概率上下文无关文法、最大
似然训练、依存语法树等）；语义分析关键知识点包含自然语言中语义分析等基础理论知识等（如语义脚色、语义脚色标注、基于句法树方法等）；词向量主要包括基于神经网络的自然语言处罚技艺与基础理论知识等（如Word2vec词向量、
基于循环神经网络讲话模型等）。尽力跟踪自然语言处罚的起色头绪、技术理论、家当收效并以详确的形态进行浮现教学。
六、课程目标
经历相关教学活动，帮助学徒清楚自然语言处理的核心概念、任务和方法，设备从数理基础到实践行使的满堂思想框架，培育学徒深切思索，知行合一的科学思想方法，提高学徒对付自然语言处罚技艺的清楚与行使能力。
课程的全部倾向包含：
目标1：使学徒掌握自然语言处理基本思想原理、流行算法和技术，珍视讲述自然语言处罚中经典劳动：汉文讲话基本处罚（分词、词性标注、定名实体识
别等）及典型自然语言处罚相干应用问题等。同期，将对策与理论（统计机器学习理论/计算练习理论/数据挖掘理论/信息学理论）紧密结合，掌握自然语言处罚的基本思维、概念和多见算法；为毕业条件1提供支持。
倾向2：使学生清楚概率论、统计、认知科学等基础交叉学科学问和思维在计算机相关题目的建模发挥的感化，清楚相干模型的思想本质，学徒对自然语言界线的研究对象、研究倾向和研究方法有全局性的了解；为毕业要求1提供缓助。
倾向3：经历习题讨论、实验和课程设计，使学徒加强理论思维和学问，培养学徒分析模型、起头实现自然语言处罚中不同任务和行使，以及解放科研与实
际问题的能力。这必要经历练习掌握新技艺和新对策才情做，从而锻炼自立学习的实力。为结业要求12提供支持。
目标4：能相识到计算机技术日新月异的起色特征，以我们课程所介绍的人工智能、大数据、自然语言处理为例，使学徒认可自主学习和一生学习的必要性。为结业要求12提供支持。
七、课程目标对结业要求的支撑干系八、教学设想及对课程目标的支持
第一章自然语言处理综述
本章关键介绍人工智能发展历史综述，不同领域自然语言处罚应用题目及对策等，自然语言处罚基础技术方法概述，其中包含部分机器学习学问，自然语言处罚条理架构，具体任务介绍，歧义问题，经验主义对策等。
1.教导倾向
1）了解自然语言处理主要行使；2）了解自然语言处理基础技术对策；本章教学缓助课程目标1和课程目标4。
2.教学核心
机器学习学问。
3.教导难点
学习概率论中相干学问思维，行使分析解放实践自然语言中题目。4.教学枢纽设想
团结当代机器学习以及自然语言处理的发展，进展文献观赏与探讨，较全数地介绍自然语言处理界线的核心概念、劳动和对策。
5.思政元素
自然语言处罚是研究人类讲话的学科，是人工智能领域王冠上的明珠。自然语言处理涉及到诸多算法和技艺，而且发展日新月异，因此，为了更好的研究自然语言处罚，必要竖立一生学习观点；工匠精力是精益求精的态度、是刻苦耐劳的品行、是与时俱进的品质，科学研究需要工匠精力，动作科研工作者或工程师，我们必要从一开始就树立和培育工匠精神。
第二章基本数学及信息学理论
本章的主要知识点包括概率论基本及信息论基础以及线性代数，最大似然估计等机器练习学问与对策。
概率Probability，前提概率ConditionalProbability，期许Expectation，方差Variance，标准差Deviation，协方差
Covariance，二项分布BinomialDistribution，高斯分布Gaussian
Distribution等;
熵Entropy，联合熵JointEntropy，前提熵ConditionalEntropy，互信息MutualInformation，KL散度KL-Divergence，交错熵Cross
Entropy
最大似然估计MaximumLikelihoodEstimation；
梯度下降GradientDescent；
参数练习ParameterEstimation；
1.教学目标
1)了解线性代数等基础数学知识；2）领略概率论基本；
3）了解信息论基本；
本章教导支持的课程目标为倾向1和目标2。
2.教学核心
统计概率论基础。
经历上述实质的教学，使学生领略统计概率论的核心概念和应用对策。
3.教导难点
经典概率论学问：前提概率，贝叶斯定理，期许，方差，标准差，协方差，二项分布，高斯分布等。
4.教学枢纽设计