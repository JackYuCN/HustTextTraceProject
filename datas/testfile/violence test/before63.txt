《自然语言处理》课程大纲
一、课程名称：自然语言处理
二、课程性质：选修、理论课
三、学时与学分：40学时（理论学时：32，实验学时：8），2.5学分
四、课程先导课：线性代数（或矩阵论），概率论与数理统计，微积分，Ｃ语言程序设计（或python/java/c++任何一种编程语言），算法设计与分析
五、课程简介
“自然语言处理”是一门兼顾理论性与实践性的课程，主要包含七个重要部分：自然语言处理综述、语言模型（N-gram语言模型）、序列标注问题(Sequence
labellingproblem)、句法分析、语义分析、情感分析、词向量等。其中：自然语言处理综述主要介绍人工智能发展历史综述，不同领域自然语言处理应用问题及方法等，自然语言处理基本技术方法概述，其中包括部分机器学习知识，自然语
言处理层次架构，具体任务介绍，歧义问题，经验主义方法等；语言模型主要包括自然语言处理相关语言模型基础理论以及相关平滑处理技术等（如N-Gram；链式规则ChainRule等）；序列标注问题(Sequencelabellingproblem)主要知识
点包括序列标注学习及其相关应用等（如离散/连续马尔科夫模型、中文分词、词性标注、命名实体识别等）；句法分析主要包括自然语言中语法分析等基础理论知识等（如上下文无关文法、自上而下句法分析、概率上下文无关文法、最大
似然训练、依存语法树等）；语义分析主要知识点包括自然语言中语义分析等基础理论知识等（如语义角色、语义角色标注、基于句法树方法等）；词向量主要包括基于神经网络的自然语言处理技术与基础理论知识等（如Word2vec词向量、
基于循环神经网络语言模型等）。力求跟踪自然语言处理的发展脉络、技术理论、产业成果并以翔实的形态进行展现教学。
六、课程目标
通过相关教学活动，帮助学生理解自然语言处理的核心概念、任务和方法，建立从数理基础到实际应用的整体思维框架，培养学生深入思考，知行合一的科学思维方法，提高学生对于自然语言处理技术的理解与应用能力。
课程的具体目标包括：
目标1：使学生掌握自然语言处理基本思想原理、流行算法和技术，着重讲述自然语言处理中经典任务：中文语言基本处理（分词、词性标注、命名实体识
别等）及典型自然语言处理相关应用问题等。同时，将方法与理论（统计机器学习理论/计算学习理论/数据挖掘理论/信息学理论）紧密结合，掌握自然语言处理的基本思想、概念和常见算法；为毕业要求1提供支持。
目标2：使学生理解概率论、统计、认知科学等基础交叉学科知识和思想在计算机相关问题的建模发挥的作用，理解相关模型的思想本质，学生对自然语言领域的研究对象、研究目标和研究方法有全局性的了解；为毕业要求1提供支持。
目标3：通过习题讨论、实验和课程设计，使学生巩固理论思想和知识，培养学生分析模型、动手实现自然语言处理中不同任务和应用，以及解决科研与实
际问题的能力。这需要通过学习掌握新技术和新方法才能做，从而锻炼自主学习的能力。为毕业要求12提供支持。
目标4：能认识到计算机技术日新月异的发展特点，以我们课程所介绍的人工智能、大数据、自然语言处理为例，使学生认同自主学习和终身学习的必要性。为毕业要求12提供支持。
七、课程目标对毕业要求的支撑关系八、教学设计及对课程目标的支持
第一章自然语言处理综述
本章主要介绍人工智能发展历史综述，不同领域自然语言处理应用问题及方法等，自然语言处理基本技术方法概述，其中包括部分机器学习知识，自然语言处理层次架构，具体任务介绍，歧义问题，经验主义方法等。
1.教学目标
1）了解自然语言处理主要应用；2）了解自然语言处理基本技术方法；本章教学支持课程目标1和课程目标4。
2.教学重点
机器学习知识。
3.教学难点
学习概率论中相关知识思想，应用分析解决实际自然语言中问题。4.教学环节设计
结合现代机器学习以及自然语言处理的发展，开展文献阅读与讨论，较全面地介绍自然语言处理领域的核心概念、任务和方法。
5.思政元素
自然语言处理是研究人类语言的学科，是人工智能领域皇冠上的明珠。自然语言处理涉及到诸多算法和技术，而且发展日新月异，因此，为了更好的研究自然语言处理，需要树立终身学习观念；工匠精神是精益求精的态度、是刻苦耐劳的品格、是与时俱进的品质，科学研究需要工匠精神，作为科研工作者或工程师，我们需要从一开始就树立和培育工匠精神。
第二章基本数学及信息学理论
本章的主要知识点包括概率论基础及信息论基础以及线性代数，最大似然估计等机器学习知识与方法。
概率Probability，条件概率ConditionalProbability，期望Expectation，方差Variance，标准差Deviation，协方差
Covariance，二项分布BinomialDistribution，高斯分布Gaussian
Distribution等;
熵Entropy，联合熵JointEntropy，条件熵ConditionalEntropy，互信息MutualInformation，KL散度KL-Divergence，交叉熵Cross
Entropy
最大似然估计MaximumLikelihoodEstimation；
梯度下降GradientDescent；
参数学习ParameterEstimation；
1.教学目标
1)了解线性代数等基本数学知识；2）了解概率论基础；
3）了解信息论基础；
本章教学支持的课程目标为目标1和目标2。
2.教学重点
统计概率论基础。
通过上述内容的教学，使学生了解统计概率论的核心概念和应用方法。
3.教学难点
经典概率论知识：条件概率，贝叶斯定理，期望，方差，标准差，协方差，二项分布，高斯分布等。
4.教学环节设计